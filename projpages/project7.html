<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Autonomous Robot Navigation Localization - Taylor Tam</title>
  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" />
  <!-- Google Font -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet" />
  <!-- External CSS -->
  <link rel="stylesheet" href="../style.css" />
</head>
<body>
  <!-- Header / Navigation -->
  <header>
    <div class="container d-flex align-items-center justify-content-between">
      <a href="../index.html" class="logo">
        <img src="../imgs/pilogo.png" alt="Taylor Tam Logo" />
      </a>
      <nav>
        <a href="../index.html#about">About</a>
        <a href="../index.html#projects">Projects</a>
        <a href="../index.html#contact">Contact</a>
      </nav>
    </div>
  </header>
  
  <!-- Spacer between header and main content -->
  <div style="height: 50px;"></div>
  
  <!-- Main Project Content -->
  <main class="container">
    <br>
    <h1>Autonomous Robot Navigation Localization</h1>
    <p>
      Developed a custom localization program for autonomous robot navigation by integrating a computer vision pipeline with custom blob detection, angle correction, and color detection. In this project, I served as the lead software engineer and collaborated with a multidisciplinary team of electrical and mechanical engineers.
    </p>
    
    <h2>Project Overview</h2>
    <p>
      The goal of this project was to create a robust and efficient localization system that enables autonomous robots to navigate accurately in complex environments. By leveraging computer vision techniques, the system processes live video feeds to detect, track, and correct the robot’s trajectory in real time.
    </p>
    
    <h2>Key Features</h2>
    <ul>
      <li>Custom computer vision pipeline for robust localization</li>
      <li>Blob detection for precise object and feature identification</li>
      <li>Angle correction and color detection to enhance positional accuracy</li>
      <li>Cross-disciplinary collaboration with electrical and mechanical engineers</li>
    </ul>
    
    <h2>Technical Details</h2>
    <p>
      The system employs a computer vision pipeline designed to process video input and identify relevant features using custom blob detection algorithms. Angle correction algorithms adjust the robot’s orientation, while color detection helps in distinguishing landmarks for accurate localization. This integrated approach enables real-time navigation and improved autonomous decision-making in challenging environments.
    </p>
    
    <p>
      <a href="../index.html#projects" class="btn btn-primary">Back to Projects</a>
    </p>
  </main>
  
  <!-- Footer -->
  <footer>
    <div class="container">
      <p class="mb-0">&copy; 2025 Taylor Tam</p>
    </div>
  </footer>
  
  <!-- Bootstrap JS Bundle with Popper -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
